# LLM Model Configuration
# Central configuration for all model usage across the project

default:
  model: "gpt5_mini"  # PRIMARY MODEL - reasoning capability with good cost efficiency
  max_tokens: 1000
  temperature: 0.0  # Deterministic for consistent classification
  # Pricing: $0.25/$2.00 per 1M tokens (input/output), $0.025 cached (90% discount)
  # Previous: gpt4o_mini ($0.15/$0.60) - switched for reasoning capability

# Alternative models for specific use cases or experiments
models:
  # Anthropic Claude Models
  opus:
    model: "anthropic/claude-3-opus-20240229"
    max_tokens: 1000
    temperature: 0.0
    description: "Premium model - highest quality, use for difficult cases"

  haiku:
    model: "anthropic/claude-3-haiku-20240307"
    max_tokens: 1000
    temperature: 0.0
    description: "Ultra-fast model - maximum cost optimization, good quality"

  sonnet:
    model: "anthropic/claude-3-5-sonnet-20241022"
    max_tokens: 1000
    temperature: 0.0
    description: "Balanced model - cost-optimized, fast, high quality"

  sonnet_legacy:
    model: "anthropic/claude-3-sonnet-20241022"
    max_tokens: 1000
    temperature: 0.0
    description: "Legacy sonnet model - may not be available"

  # OpenAI GPT Models

  # GPT-5 Series (August 2025 - Latest flagship with reasoning)
  gpt5:
    model: "openai/gpt-5"
    max_tokens: 1000
    temperature: 0.0
    description: "GPT-5 flagship - advanced reasoning, 90% cache discount"
    pricing: "$1.25/$10.00 per 1M tokens (input/output), $0.125 cached"
    context: "400K tokens, 128K max output"

  gpt5_mini:
    model: "openai/gpt-5-mini"
    max_tokens: 1000
    temperature: 0.0
    description: "GPT-5 mini - fast reasoning, cost-effective"
    pricing: "$0.25/$2.00 per 1M tokens (input/output), $0.025 cached"

  gpt5_nano:
    model: "openai/gpt-5-nano"
    max_tokens: 1000
    temperature: 0.0
    description: "GPT-5 nano - ultra-fast, cheapest option for summarization/classification"
    pricing: "$0.05/$0.40 per 1M tokens (input/output), $0.005 cached"

  # GPT-4.1 Series (April 2025 - Latest general-purpose)
  gpt41:
    model: "openai/gpt-4.1"
    max_tokens: 1000
    temperature: 0.0
    description: "GPT-4.1 - latest general-purpose multimodal, improved coding"
    pricing: "~$3.00/$10.00 per 1M tokens (estimated)"

  gpt41_mini:
    model: "openai/gpt-4.1-mini"
    max_tokens: 1000
    temperature: 0.0
    description: "GPT-4.1 Mini - cost-effective general-purpose"
    pricing: "~$0.30/$1.00 per 1M tokens (estimated)"

  # GPT-4o Series (Current production default)
  gpt4o_mini:
    model: "openai/gpt-4o-mini"
    max_tokens: 1000
    temperature: 0.0
    description: "GPT-4o mini - CURRENT DEFAULT - best cost/quality balance"
    pricing: "$0.15/$0.60 per 1M tokens (input/output), $0.075 cached"

  gpt4o:
    model: "openai/gpt-4o"
    max_tokens: 1000
    temperature: 0.0
    description: "GPT-4o - CURRENT PREMIUM - used for taxonomy generation"
    pricing: "$2.50/$10.00 per 1M tokens (input/output)"

  # o-Series Reasoning Models (2024-2025)
  o4_mini:
    model: "openai/o4-mini"
    max_tokens: 1000
    temperature: 0.0
    description: "o4-mini - latest compact reasoning model, excellent for math/coding"
    pricing: "$0.20/$0.80 per 1M tokens (input/output)"

  o3_mini:
    model: "openai/o3-mini"
    max_tokens: 1000
    temperature: 0.0
    description: "o3-mini - cost-efficient STEM reasoning, replaces o1-mini"
    pricing: "$1.10/$4.40 per 1M tokens (input/output)"

  o3:
    model: "openai/o3"
    max_tokens: 1000
    temperature: 0.0
    description: "o3 - advanced reasoning for complex multi-faceted analysis"
    pricing: "~$15.00/$60.00 per 1M tokens (estimated)"

  o1_mini:
    model: "openai/o1-mini"
    max_tokens: 1000
    temperature: 0.0
    description: "o1-mini - legacy reasoning model, use o3-mini instead"
    pricing: "$3.00/$12.00 per 1M tokens (input/output)"

  o1:
    model: "openai/o1"
    max_tokens: 1000
    temperature: 0.0
    description: "o1 - advanced reasoning model"
    pricing: "$15.00/$60.00 per 1M tokens (input/output)"

  o1_pro:
    model: "openai/o1-pro"
    max_tokens: 1000
    temperature: 0.0
    description: "o1-pro - MOST EXPENSIVE - extreme difficulty reasoning tasks only"
    pricing: "$150.00/$600.00 per 1M tokens (input/output)"

  # Legacy Models (still available but superseded)
  gpt4_turbo:
    model: "openai/gpt-4-turbo-preview"
    max_tokens: 1000
    temperature: 0.0
    description: "GPT-4 Turbo - LEGACY - more expensive than GPT-4o, use GPT-4o instead"
    pricing: "$10.00/$30.00 per 1M tokens (input/output)"

  gpt35_turbo:
    model: "openai/gpt-3.5-turbo"
    max_tokens: 1000
    temperature: 0.0
    description: "GPT-3.5 Turbo - LEGACY - budget option, use GPT-4o-mini instead"
    pricing: "$0.50/$1.50 per 1M tokens (input/output)"

# Experiment-specific configurations
experiments:
  temperature_test:
    model: "anthropic/claude-3-opus-20240229"
    max_tokens: 1000
    temperature: 0.7
    description: "Testing temperature effects on classification"

  batch_processing:
    model: "anthropic/claude-3-opus-20240229"
    max_tokens: 2000  # Larger context for batch classification
    temperature: 0.0
    description: "Configuration for batch processing multiple products"

# API configuration
api:
  retry_attempts: 3
  initial_retry_delay: 30  # seconds
  exponential_backoff: true
  rate_limit_delay: 60  # seconds between products

# Use case specific configurations
use_cases:
  product_classification:
    default_model: "gpt4o_mini"
    max_tokens: 1000
    temperature: 0.0
    batch_size: 10
    retry_on_parse_error: true

  health_quiz:
    default_model: "gpt5_mini"  # Reasoning capability for better health recommendations
    max_tokens: 1000
    temperature: 0.0  # Deterministic for medical consistency
    # Pricing: $0.25/$2.00 per 1M tokens (~$0.00042 per quiz with 740 tokens)
    # Previous: gpt4o_mini (~$0.00025 per quiz) - 68% more cost but adds reasoning
    max_recommendations: 5
    min_relevance_score: 0.3
    include_educational_content: true
    consultation_threshold: 7  # Severity level triggering consultation recommendation
    response_format: "json"  # Structured output format
    # WordPress/WooCommerce URL Configuration
    # TESTED: ID-based URLs don't work (?product=ID, /product/ID/ all return 404)
    # WORKING: Slug-based URLs work (e.g., /product/hemp-adapt-2oz/)
    # IMPLEMENTATION: Algorithmic slug generation from product titles
    product_url_template: "https://rogueherbalist.com/product/{product_slug}/"
    # Fallback if slug generation fails:
    # product_url_template: "https://rogueherbalist.com/shop/"

    # UTM Tracking Configuration (for web and email, NOT CLI reports)
    utm_tracking:
      enabled: true
      utm_source: "health_quiz"
      utm_campaign: "health_quiz_recommendations"
      # utm_medium is set dynamically: 'email' or 'web'
      # utm_content is set to product_slug
      # utm_term is optionally set to primary_health_area

  taxonomy_generation:
    default_model: "gpt5"  # Premium quality with 90% cache discount for repeated elements
    max_tokens: 128000  # GPT-5 allows up to 128K output tokens
    temperature: 0.1  # Slight creativity for improvements while maintaining consistency
    validation_retries: 3  # Number of retry attempts if validation fails
    include_diff_report: true  # Generate diff reports comparing before/after
    document_format: "xml"  # Expected document format
    preserve_structure: true  # Maintain original XML structure and hierarchy
    chunk_size: 3  # Maximum taxons per chunk (including subcategories)
    # GPT-5: $1.25/1M input + $10.00/1M output tokens (~$0.40 for full taxonomy)
    # 90% cache discount: $0.125/1M for cached input (vs GPT-4o 50% at $1.25)
    # Savings: 29% cheaper than GPT-4o ($0.56 → $0.40) + better caching
    # Previous: gpt4o ($2.50/$10.00, 16K output limit, no cache discount)

  seo_generation:
    default_model: "gpt4o"  # Premium quality for SEO metadata
    max_tokens: 2000  # Small - only generating <seo> block (~15 lines)
    temperature: 0.1  # Consistent SEO generation
    validation_retries: 3  # Number of retry attempts if validation fails
    validate_urls: true  # Check canonical URLs actually work (HTTP HEAD request)

    # SEO field specifications
    fields:
      focus-keyword:
        required: true
        max_chars: 40
        description: "2-4 word keyword phrase, more specific for subcategories"

      meta-title:
        required: true
        max_chars: 60
        suffix: " | Rogue Herbalist"
        description: "Page title for search results, includes brand"

      meta-description:
        required: true
        max_chars: 160
        description: "Search result description, benefit-driven, mentions 2-3 ingredients"

      h1:
        required: true
        max_chars: 70
        description: "Main page heading, include focus keyword"

      og-title:
        required: true
        max_chars: 90
        description: "Social sharing title, more engaging than meta-title"

      og-description:
        required: true
        max_chars: 300
        description: "Social sharing description, conversational"

      keywords:
        required: true
        max_chars: 120
        description: "5-10 comma-separated keywords"

      canonical-url:
        required: true
        description: "Full canonical URL for the page"

      schema-type:
        required: true
        default: "CollectionPage"
        description: "Schema.org type"

    # URL templates for different element types
    url_templates:
      primary: "https://rogueherbalist.com/category/{slug}/"
      subcategory: "https://rogueherbalist.com/category/{parent_slug}/{slug}/"
      product: "https://rogueherbalist.com/product/{slug}/"
      default: "https://rogueherbalist.com/{slug}/"

    # Element-specific XPath for finding elements to enhance
    element_xpath: ".//taxon"  # For taxonomies; change to ".//product" for product catalogs

    # Pricing Analysis (GPT-4o):
    # $2.50/1M input + $10.00/1M output tokens
    # ~87 calls for full taxonomy: 87 × (800 input + 200 output) = ~$0.26
    # Alternative: gpt5_nano ($0.05/$0.40) = ~$0.04 for full taxonomy (85% cheaper)

# Client-aware cost tracking configuration
client_tracking:
  client: "get-better-care"
  use_case: "herbal-classification"
  project: "ic-ml"
  environment: "production"
  tags:
    - "herbal-products"
    - "classification"
    - "taxonomy-based"

# Legacy metadata (kept for compatibility)
metadata:
  client: "rogue_herbalist"
  business: "get_better_care"